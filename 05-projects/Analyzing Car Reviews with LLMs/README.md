# ğŸš— Analyzing Car Reviews with LLMs

**Car-ing is Sharing â€” LLM Prototype Project**

## ğŸ“Œ Overview

This project is a **proof-of-concept chatbot backend** built for *Car-ing is Sharing*, a car sales and rental company.
It demonstrates how **Large Language Models (LLMs)** can be leveraged to handle diverse customer-facing NLP tasks such as:

* Sentiment analysis and evaluation
* Machine translation and quality assessment
* Extractive question answering
* Text summarization

The pipeline processes a small dataset of car reviews and produces structured outputs and evaluation metrics that can later be integrated into a chatbot or customer insights platform.

---

## ğŸ¯ Objectives

The prototype fulfills the following tasks:

### 1ï¸âƒ£ Sentiment Classification

* Use a **pre-trained sentiment analysis LLM** to classify the sentiment of **five car reviews** from `car_reviews.csv`
* Store raw model outputs in `predicted_labels`
* Convert predictions into binary labels `{0,1}` stored in `predictions`
* Evaluate performance using:

  * **Accuracy** â†’ `accuracy_result`
  * **F1 Score** â†’ `f1_result`

---

### 2ï¸âƒ£ English â†’ Spanish Translation + Evaluation

* Extract the **first two sentences** of the **first review**
* Translate the text using an **English-to-Spanish translation LLM**
* Store the translated output in `translated_review`
* Evaluate translation quality using **BLEU score**

  * References provided in `reference_translations.txt`
  * Store metric in `bleu_score`

---

### 3ï¸âƒ£ Extractive Question Answering

* Focus on the **second review**, which highlights brand aspects
* Use an extractive QA model:

  ```
  deepset/minilm-uncased-squad2
  ```
* Ask the question:

  ```
  "What did he like about the brand?"
  ```
* Use:

  * `question` â†’ the query
  * `context` â†’ the review text
* Store the extracted answer in `answer`

---

### 4ï¸âƒ£ Review Summarization

* Summarize the **last review** in the dataset
* Target length: **~50â€“55 tokens**
* Store output in `summarized_text`

---

## ğŸ§  Models Used

| Task               | Model Type                        |
| ------------------ | --------------------------------- |
| Sentiment Analysis | Pre-trained sentiment classifier  |
| Translation        | English â†’ Spanish translation LLM |
| Question Answering | `deepset/minilm-uncased-squad2`   |
| Summarization      | Pre-trained summarization LLM     |

All models are loaded via **Hugging Face Transformers**.

---

## ğŸ“ Project Structure

```
Analyzing-Car-Reviews-with-LLMs/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ car_reviews.csv                # Input dataset (5 car reviews)
â”‚   â””â”€â”€ reference_translations.txt     # Reference translations for BLEU
â”‚
â”œâ”€â”€ main.ipynb                             # Runs all tasks end-to-end
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ README.md
```

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run the Full Pipeline

```bash
open main.ipynb
```

This will:

* Load the dataset
* Execute all LLM tasks
* Compute evaluation metrics

---

## ğŸ“Š Outputs & Variables

| Variable            | Description                            |
| ------------------- | -------------------------------------- |
| `predicted_labels`  | Raw sentiment predictions from the LLM |
| `predictions`       | Binary sentiment labels `{0,1}`        |
| `accuracy_result`   | Sentiment classification accuracy      |
| `f1_result`         | Sentiment classification F1 score      |
| `translated_review` | Spanish translation of review text     |
| `bleu_score`        | BLEU score for translation quality     |
| `question`          | QA input question                      |
| `context`           | QA context (review text)               |
| `answer`            | Extracted QA answer                    |
| `summarized_text`   | ~50â€“55 token review summary            |

---

## ğŸ› ï¸ Dependencies

Key libraries used:

* `transformers`
* `torch`
* `pandas`
* `scikit-learn`
* `nltk`
* `evaluate`

---

## ğŸš€ Future Extensions

* Wrap pipelines into a **FastAPI chatbot backend**
* Add **multi-language sentiment analysis**
* Store results in a vector database for retrieval
* Integrate conversational memory (RAG)

---

## ğŸ“„ License

MIT License

---
